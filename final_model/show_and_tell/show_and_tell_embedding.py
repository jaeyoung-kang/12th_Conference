# -*- coding: utf-8 -*-
"""show_and_tell_proprecess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SVEuoI16BsoQNpo8TllUlhJ3ynNb-C8v
"""


import torch
from torch.utils.data import Dataset, DataLoader
from torch import nn
from torchvision import transforms
import torchvision.datasets as datasets
import torchvision.models as models # 임베딩 모델
import torchvision
import torch.optim as optim
import pickle
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import os
from kor2vec import Kor2Vec # Kor2Vec import
from show_and_tell_proprecess import *
from show_and_tell_model import *
from show_and_tell_train import *

embedding_dir="review_embeddings_test.pickle"

show_and_tell_model.load_state_dict(torch.load(model_dir+py_dir+model_name))
# 가장 유사한, 가장 유사하지 않은 것 비교 코드

if embedding_dir not in os.listdir(model_dir+py_dir): #임베딩 파일 없을 경우 생성 후 저장
  i_list = []
  #resnet_embed_list = []
  embed_list = []

  # 모든 이미지에 대한 임베딩 계산
  for i, data in enumerate(reveiw_train_data):
      show_and_tell_model.eval()
      
      img, label = data[0].to(device), data[1].to(device)
      img = img.unsqueeze(0)
      #resnet_embed = show_and_tell_model.give_resnet_embedding(img)[0].cpu().detach().numpy()[0][0]
      embed = show_and_tell_model.give_embedding(img).cpu().detach().numpy()

      i_list.append(i)
      embed_list.append(embed)
      #resnet_embed_list.append(resnet_embed)

      if i>= len(reveiw_train_data) - 1: break

      if i%100 == 0:
        print(f"image done : {i}")


  # review_save
  with open(model_dir+py_dir+embedding_dir, 'wb') as f:
      pickle.dump(embed_list, f, pickle.HIGHEST_PROTOCOL)

else: #임베딩 파일 있을 경우 불러오기
  with open(model_dir+py_dir+embedding_dir, 'rb') as f:
      embed_list = pickle.load(f)